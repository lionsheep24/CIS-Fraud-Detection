{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What worked\n",
    "   - UID 를 찾는 것\n",
    "     -  Keys to identifying UID : card1, addr1, and D1(days since client (credit card) began).\n",
    "     -  D1n = TransactionDay -  D1 : 카드 개시일\n",
    "        - Where TransactionDay = TransactionDT / (24 * 60* 60) ).\n",
    "     - D3n = TransactionDay - D3 : 마지막 카드 거래일\n",
    "     - 같은 방법으로 DXn = TransactionDay - DX\n",
    "     - UID 검증 : UID 로 Groupby 한 데이터들의 D15n 의 표준편차가 0이 아니면 UID 예측은 잘못된 것. \n",
    "     - Feature Engineering\n",
    "     - UID 로 Groupby --> Aggregated Feature를 만드는 것(Group Feature)\n",
    "   - Frequency Encoding \n",
    "   - CatBoost / XGB 등 다양한 모델로 Stacking\n",
    "   - CV Scheme 은 중요하다\n",
    "   - Train / Test 가 시간순으로 배열되어 있으므로\n",
    "   - CV Examples(Time Series)\n",
    "     - 0 | 2 3 4 5 6\n",
    "     - 0 1 | 3 4 5 6\n",
    "     - 0 1 2 | 4 5 6\n",
    "     - 0 1 2 3 | 5 6\n",
    "   - Define Validation Set matters\n",
    "     - Adversarial validation\n",
    "        - Covariate Shift\n",
    "          - Feature 의 train 과 test distribution 이 다르다면 test performance 가 불안정할 수 있다\n",
    "          - 따라서 어떤 Feature 가 train 과 test 에서 다른 분포를 보이는지 확인 필요 \n",
    "          - 확인하고자 하는 Feature만 이용해 train 에 포함되는지 test 에 포함되는지 확인 위해 lightGBM 으로 AUC 확인해본다\n",
    "          - 이때 AUC 는 istest = 0 / 1 을 맞추는 binary classification\n",
    "          - AUC 가 0.5 에 가까울수록 train/test 간 distribution 에 차이는 없다.\n",
    "          \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariate_shift(feature):\n",
    "    df_card1_train = pd.DataFrame(data={feature: train[feature], 'isTest': 0})\n",
    "    df_card1_test = pd.DataFrame(data={feature: test[feature], 'isTest': 1})\n",
    "\n",
    "    # Creating a single dataframe\n",
    "    df = pd.concat([df_card1_train, df_card1_test], ignore_index=True)\n",
    "    \n",
    "    # Encoding if feature is categorical\n",
    "    if str(df[feature].dtype) in ['object', 'category']:\n",
    "        df[feature] = LabelEncoder().fit_transform(df[feature].astype(str))\n",
    "    \n",
    "    # Splitting it to a training and testing set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[feature], df['isTest'], test_size=0.33, random_state=47, stratify=df['isTest'])\n",
    "\n",
    "    clf = lgb.LGBMClassifier(**params, num_boost_round=500)\n",
    "    clf.fit(X_train.values.reshape(-1, 1), y_train)\n",
    "    roc_auc =  roc_auc_score(y_test, clf.predict_proba(X_test.values.reshape(-1, 1))[:, 1])\n",
    "\n",
    "    del df, X_train, y_train, X_test, y_test\n",
    "    gc.collect();\n",
    "    \n",
    "    return roc_auc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
